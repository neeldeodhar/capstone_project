import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from capstone_project import analyzer


def score(y_true: np.ndarray, y_predicted: np.ndarray) -> float:
    accuracy_score = accuracy_score(y_true, y_predicted)
    return accuracy_score

def plot_confusion_matrix(self):
        CM = confusion_matrix(self.y_test, self.y_pred)
        sns.heatmap(cm, annot = True, cmpap = 'Blues')
        return CM  
class Classifier: 
    def __init__(self, random_state: int, params: dict):
        #self.X_test = X_test
       # self.X_train = X_train
        
        #self.y_test = y_test
       # self.y_train = y_train
       # self.n_estimators = 10
       # self.max_depth = 10
       self.random_state = random_state
       self.model = self.create_model()
       self.params = params
    def create_model():
        return None

    def fit(self, x_train: np.ndarray, y_train: np.ndarray, params: dict):
       # self.model = RandomForestClassifier(n_estimators= self.n_estimators, max_depth = self.max_depth, random_state = 42)
        #self.model.fit(self.X_train, self.y_train)
        self.model.fit(X_train, y_train, **params)
    def predict(self, x: np.ndarray) -> np.ndarray:
        predict_results = self.model.predict(x)
        return predict_results
    def split_data(self):
        self.X_train = self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = self.custom_param, random_state =42)
    def score(self, x:np.ndarray, y_true: ndarray) ->float:
        y_predicted = self.predict(x)
        accuracy_score = accuracy_score(y_true, y_predicted)
        return accuracy_score

class LogisticRegression(Classifier):
    def __init__(self, random_state: int, params: dict):
        super().__init__(random_state = random_state, params = params)
    def create_model(self)-> LogisticRegression:
        model = LogisticRegression(**self.params)
        return model

class Random_Classifier(Classifier):
    def __init__(self, n_estimators: int, criterion: str, max_depth: int):
        super().__init__(n_estimators = n_estimators, criterion = criterion, max_depth = max_depth, params = params)
       # self.test_size = test_size
   # def split_data(self):
      #  self.X_train = self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = self.custom_param, random_state =42)
    def createRC_model(self)-> Random_Classifier:
        RC_model = Random_Classifier(**self.params)
        return RC_model
class DecisionTree(Classifier):
    def __init__(self, criterion:str, random_state:int, max_depth: int):
       # self.criterion = criterion
        #self.random_state = random_state
        #self.max_depth = max_depth
        super().__init__(random_state = random_state, max_depth = max_depth, criterion = criterion, params = params)
    def createDT_model(self)-> DecisionTreeClassifier:
        DTC = DecisionTreeClassifier (**self.params)
       # DCT.fit(X_train, y_train)
        return DTC   
class SVC_classifier(Classifier):        
    def __init__(self, criterion:str, random_state:int, max_depth: int):
        self.criterion = criterion
        self.random_state = random_state
        self.gamma = gamma
        self.kernel = kernel 
    def SVC (X_train, X_test, y_train):
        scoreSVC = []

        svm = SVC(kernel = 'rbf', gamma = 'auto', C = 0.2, random_state = 0).fit(X_train, y_train)
        y_pred = svm.predict(X_test)
        return svm




if __name__ =="__main__":
   
  #  RFM = Random_Classifier(0.2)
   # RFM.split_data()
    #RFM.fit(RFM.X_train, RFM.y_train)
    params = {"criterion": "lbgs"}
    logistic_regression = LogisticRegression (params = params)