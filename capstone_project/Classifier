import pandas as pd
import numpy as np
from numpy import ndarray
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from capstone_project import analyzer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#from tensorflow.keras.models import Sequential 

def main():
    absolute_path = "C:/Users/ideod/OneDrive/Documents/new folder zip data/diamonds.csv"
    dfdf = analyzer.read_dataset(csv_file_path=absolute_path)
    data_manipulation = analyzer.DataManipulation(dfdf)

    y = dfdf['cut']    
    selected_features = dfdf[['carat', 'depth', 'table', 'price' ]]
    
    encoder = LabelEncoder()
    Y = encoder.fit_transform(y)
    
    
    scaler = StandardScaler()
    X = scaler.fit_transform(selected_features)
    X_train, X_test_val, Y_train, Y_test_val = train_test_split(X, Y, test_size=0.2, random_state=45)
    X_test, X_val, Y_test, Y_val = train_test_split(X_test_val, Y_test_val, test_size=0.5, random_state=45)
  
    
    X_trainscale = scaler.fit_transform(X_train)
    X_testscale = scaler.transform(X_test)
    
    score_dict = {}
    LRC = MyLogisticRegression(random_state= 0, params={})
    LRC.fit(X_train, Y_train , None)
    score_dict ["Logistic Regression"] = LRC.score(X_test, Y_test)
    
    print(score_dict)
    
 # def __init__(self, n_estimators: int, criterion: str, max_depth: int):
 #   RandClass = MyRandom_Classifier(params={}, n_estimators= None, criterion ='gini', max_depth= None, random_state = None)
 #   RandClass.fit(X_train, Y_train , None)
 #   score_RC ["Random Classifier"] = RandClass.score(X_test, Y_test)
    
  #  print(score_RC)
    score_DTC = {}
   # DTC = MyDecisionTree(random_state= 0, params={})
    DTC = MyDecisionTree(random_state= 0, criterion= 'gini', max_depth = None, params = {})
    DTC.fit(X_train, Y_train , None)
    score_DTC["Decision Tree"] = DTC.score(X_test, Y_test)
    
    print(score_DTC)

    score_SVC = {}
   # DTC = MyDecisionTree(random_state= 0, params={})
    SV = MySVC_classifier(kernel = None, gamma = None, random_state= 0, max_depth = None, params = {})
    SV.fit(X_train, Y_train , None)
    score_SVC["SVC"] = SV.score(X_test, Y_test)
    
    print(score_SVC)
  #  scoreSVC = svm.score(X_test,y_test)
    Y_pred = SV.predict(X_test)
    con = confusion_matrix(Y_test, Y_pred)
    print ("confusion matrix:\n",con)
  #  cmval = confusion_matrix(Y_val, Y_pred)
    cmval_display = ConfusionMatrixDisplay(con).plot()
   # ConfusionMatrixDisplay(con).plot()
  #  plt.figure(figsize =(7,7))
  #  sns.heatmap(Y_pred.corr(), annot = True)
       
    plt.show()

    score_RF = {}
   # DTC = MyDecisionTree(random_state= 0, params={})
    RF = MyRandom_Classifier(random_state= None, n_estimators= None, criterion = None, max_depth = None, params = {})
    RF.fit(X_train, Y_train , None)
    score_RF["Random Forest "] = RF.score(X_test, Y_test)
    
    print(score_RF)

    score_ANN = {}
   # DTC = MyDecisionTree(random_state= 0, params={})
    AN = MyANN_classifier(random_state= None, max_iter = None, hidden_layer_sizes = None, params = {})
    AN.fit(X_train, Y_train , None)
    score_ANN["ANN Classifier "] = AN.score(X_test, Y_test)
    
    print(score_ANN)
def  pre_processing():
    absolute_path = "C:/Users/ideod/OneDrive/Documents/new folder zip data/diamonds.csv"
    dfdf = analyzer.read_dataset(csv_file_path=absolute_path)

    data_manipulation = analyzer.DataManipulation(dfdf)
    y = dfdf['cut']    
    selected_features = dfdf[['carat', 'depth', 'table', 'price' ]]
    
    encoder = LabelEncoder()
    Y = encoder.fit_transform(y)
    
    score_dict = {}
    scaler = StandardScaler()
    X = scaler.fit_transform(selected_features)
    X_train, X_test_val, Y_train, Y_test_val = train_test_split(X, Y, test_size=0.2, random_state=45)
    X_test, X_val, Y_test, Y_val = train_test_split(X_test_val, Y_test_val, test_size=0.5, random_state=45)
  
    
    X_trainscale = scaler.fit_transform(X_train)
    X_testscale = scaler.transform(X_test)

def score(y_true: np.ndarray, y_predicted: np.ndarray) -> float:
    score = accuracy_score(y_true, y_predicted)
    return score

class Plot_confusion_matrix():
    def __init__(self, df:pd.DataFrame):
        self.df = df
    
    def plot_correlationMatrix(self, column_names):
       selected_features = self.df[column_names]
      #  selected_features = self.df(y_predicted)
      #  cmval = confusion_matrix(y_true, y_pred)
       # cmval_display = ConfusionMatrixDisplay(cmval).plot()
       plt.figure(figsize =(7,7))
       sns.heatmap(selected_features.corr(), annot = True)
       
       plt.show()
class Classifier: 
    def __init__(self, random_state: int, params: dict):
        #self.X_test = X_test
       # self.X_train = X_train
        
        #self.y_test = y_test
       # self.y_train = y_train
       # self.n_estimators = 10
       # self.max_depth = 10
       self.random_state = random_state
       self.model = self.create_model()
       self.params = params
    def create_model():
        return None

    def fit(self, X_train: np.ndarray, y_true_train: np.ndarray, params: dict):
       # self.model = RandomForestClassifier(n_estimators= self.n_estimators, max_depth = self.max_depth, random_state = 42)
        #self.model.fit(self.X_train, self.y_train)
        self.model.fit(X_train, y_true_train)
    def predict(self, X: np.ndarray) -> np.ndarray:
        predict_results = self.model.predict(X)
        return predict_results
    def split_data(self):
        self.X_train = self.X_test, self.Y_train, self.Y_test = train_test_split(X, Y, test_size = self.custom_param, random_state =42)
    def score(self, X:np.ndarray, y_true: ndarray) ->float:
        y_predicted = self.predict(X)
        score = accuracy_score(y_true, y_predicted)
        return score

              
       
    
class MyLogisticRegression(Classifier):
    def __init__(self, random_state: int, params: dict):
        super().__init__(random_state = random_state, params = params)
    def create_model(self)-> LogisticRegression:
        model = LogisticRegression()
        return model

class MyRandom_Classifier(Classifier):
    def __init__(self, n_estimators: int, random_state: int,criterion: str, max_depth: int, params: dict):
        #super().__init__(n_estimators = n_estimators, criterion = criterion, max_depth = max_depth, params = params)
        super().__init__(random_state= random_state , params = params)
       # self.test_size = test_size
        self.criterion = criterion
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.random_state = random_state
   # def split_data(self):
      #  self.X_train = self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = self.custom_param, random_state =42)
    def create_model(self)-> RandomForestClassifier:
        model = RandomForestClassifier()
        return model
class MyDecisionTree(Classifier):
    def __init__(self, criterion:str, random_state:int, max_depth: int, params: dict):
       # self.criterion = criterion
        #self.random_state = random_state
        #self.max_depth = max_depth
      #  super().__init__(random_state = random_state, max_depth = max_depth, criterion = criterion, params = params)
      #  super().__init__(random_state = random_state, params = params)
       super().__init__(random_state = random_state, params = params)
    def create_model(self)-> DecisionTreeClassifier:
        model = DecisionTreeClassifier()
       # DCT.fit(X_train, y_train)
        return model   
class MySVC_classifier(Classifier):        
    def __init__(self, kernel:str, gamma: str, random_state:int, max_depth: int, params: dict):
        #self.criterion = criterion
        
        self.gamma = gamma
        self.kernel = kernel 
        super().__init__(random_state = random_state, params = params)
    def create_model(self)-> SVC:
        model = SVC()
       # DCT.fit(X_train, y_train)
        return model

class MyANN_classifier(Classifier):
    def __init__(self, max_iter: int, random_state: int, hidden_layer_sizes: int, params:dict):
        self.max_iter = max_iter
        self.hidden_layer_sizes = hidden_layer_sizes
        super().__init__(random_state = random_state, params = params)
    def create_model(self)-> MLPClassifier:
        model = MLPClassifier()
        return model
    
    
   # def __init__(self, activation: str):
       # self.activation = activation

   # def ANN():
       # sq = Sequential()

       # sq.add(Dense(12, input_dim=8, activation='relu'))

       # sq.add(Dense(8, activation='relu'))

      #  sq.add(Dense(1, activation='sigmoid'))

       # sq.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#class MLP_Classifier(Classifier):
  #  def __init__(self, )

if __name__ =="__main__":
   main()
   
  #  RFM = Random_Classifier(0.2)
   # RFM.split_data()
    #RFM.fit(RFM.X_train, RFM.y_train)
   # absolute_path = "C:/Users/ideod/OneDrive/Documents/new folder zip data/diamonds.csv"
    #dfdf = read_dataset(csv_file_path=absolute_path)
   # params = {"criterion": "lbgs"}
    #random_state = 4
    #logreg = LogisticRegression (params = params, random_state = random_state)
    #logreg.score
  # absolute_path = "C:/Users/ideod/OneDrive/Documents/new folder zip data/diamonds.csv"
   #dfdf = analyzer.read_dataset(csv_file_path=absolute_path)
 #  absolute_path = "C:/Users/ideod/OneDrive/Documents/new folder zip data/diamonds.csv"
  # dfdf = analyzer.read_dataset(csv_file_path=absolute_path)
   #visual= Plot_confusion_matrix(dfdf)
   #selected_features = dfdf[['carat', 'depth', 'table', 'price' ]]
   #visual.plot_correlationMatrix(selected_features)
   

  # visual.plot_correlationMatrix(['carat', 'depth', 'table', 'price' ])
    